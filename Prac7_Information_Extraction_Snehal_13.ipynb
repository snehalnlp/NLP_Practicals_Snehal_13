{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prac7_Information_Extraction_Snehal_13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehalnlp/NLP_Practicals_Snehal_13/blob/main/Prac7_Information_Extraction_Snehal_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fciosQC0iZJX"
      },
      "source": [
        "#**7. Information Extraction**\n",
        "1. Part-of-Speech Tagging\n",
        "2. Chunking\n",
        "3. Chinking\n",
        "4. Named Entity Recognition\n",
        "5. Relation Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbecxjhGxhyd",
        "outputId": "4771a93e-c5a6-487a-8591-c1e4b80386f2"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkb8hVYPf7T3"
      },
      "source": [
        "#**Part of Speech Tagging**\n",
        "The part of speech explains how a word is used in a sentence. In a sentence, a word can have different contexts and semantic meanings. The basic natural language processing models like bag-of-words fail to identify these relations between words. Hence, we use part of speech tagging to mark a word to its part of speech tag based on its context in the data. It is also used to extract relationships between words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEeLHP02xlpo",
        "outputId": "e75c2456-c2a4-40e7-e745-333c0cc47403"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "  \n",
        "# convert text into word_tokens with their tags\n",
        "def pos_tagging(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    return pos_tag(word_tokens)\n",
        "  \n",
        "pos_tagging('i dont quit i dont run i never go back on my word Thats my ninja way!!! Uzumaki Naruto!')\n",
        "\n",
        "#PRP stands for personal pronoun, RB for adverb, VBD for verb past tense, DT for determiner and NN for noun."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'JJ'),\n",
              " ('dont', 'VBP'),\n",
              " ('quit', 'NN'),\n",
              " ('i', 'NN'),\n",
              " ('dont', 'VBP'),\n",
              " ('run', 'VBN'),\n",
              " ('i', 'RB'),\n",
              " ('never', 'RB'),\n",
              " ('go', 'VBP'),\n",
              " ('back', 'RB'),\n",
              " ('on', 'IN'),\n",
              " ('my', 'PRP$'),\n",
              " ('word', 'NN'),\n",
              " ('Thats', 'NNPS'),\n",
              " ('my', 'PRP$'),\n",
              " ('ninja', 'JJ'),\n",
              " ('way', 'NN'),\n",
              " ('!', '.'),\n",
              " ('!', '.'),\n",
              " ('!', '.'),\n",
              " ('Uzumaki', 'JJ'),\n",
              " ('Naruto', 'NN'),\n",
              " ('!', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTQKx_hKfisF"
      },
      "source": [
        "#**Chunking**\n",
        "Chunking is the process of extracting phrases from unstructured text and more structure to it. It is also known as shallow parsing. It is done on top of Part of Speech tagging. It groups word into “chunks”, mainly of noun phrases. Chunking is done using regular expressions.\n",
        "\n",
        "**RULE: \"Tag Noun, verb (past tense), adjective, and coordinating junction from the sentence.\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0nYU2FUzunI"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser\n",
        "\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIMJuDchKQcS"
      },
      "source": [
        "sentence = \"The Fourth Hokage Minato is YellowFlash of Konoha\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDdFjZPKf87"
      },
      "source": [
        "grammar = ('''\n",
        "    NP: {<DT>?<JJ>*<NN>} # NP\n",
        "    ''')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaI2s-_-K8ht",
        "outputId": "cdc3876e-b9e1-479e-8d5c-2ccb1ffa42d4"
      },
      "source": [
        "chunkParser = nltk.RegexpParser(grammar)\n",
        "tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "tagged"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('Fourth', 'NNP'),\n",
              " ('Hokage', 'NNP'),\n",
              " ('Minato', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('YellowFlash', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Konoha', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n1-1Ec7LANK"
      },
      "source": [
        "tree = chunkParser.parse(tagged)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOkx_pXcLFCL",
        "outputId": "5ea1feb4-bbd1-40b7-f31c-628369001706"
      },
      "source": [
        "for subtree in tree.subtrees():\n",
        "    print(subtree)\n",
        " #tree.draw()   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  Fourth/NNP\n",
            "  Hokage/NNP\n",
            "  Minato/NNP\n",
            "  is/VBZ\n",
            "  YellowFlash/NNP\n",
            "  of/IN\n",
            "  Konoha/NNP)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt5tewVlA44"
      },
      "source": [
        "#**Chinking**\n",
        "Chinking is the process of removing a sequence of tokens from a chunk. If the matching sequence of tokens spans an entire chunk, then the whole chunk is removed; if the sequence of tokens appears in the middle of the chunk, these tokens are removed, leaving two chunks where there was only one before. If the sequence is at the periphery of the chunk, these tokens are removed, and a smaller chunk remains.\n",
        "Sometimes it is easier to define what we want to exclude from a chunk. We can define a chink to be a sequence of tokens that is not included in a chunk.\n",
        "\n",
        "**RULE: This means we're removing from the chink one or more verbs, prepositions, determiners, or the word 'to'.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkVIhc3zk_3M"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY4TsLtGl-xI"
      },
      "source": [
        "sentence = \"The Seventh Hokage Naruto the son of Minato and Kushina of Konoha village and having Six Sage Path power with kurama.\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FzHvVwWl-Um"
      },
      "source": [
        "chinkgra = ('''\n",
        "    Chunk: {<.*>+}\n",
        "    }<VB.?|IN|DT|TO>+{\n",
        "    ''')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8elQMelKnCeO",
        "outputId": "718831d1-7c22-4ec6-f4a5-c0b23846e811"
      },
      "source": [
        "chinkParser = nltk.RegexpParser(chinkgra)\n",
        "tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "tagged\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('Seventh', 'NNP'),\n",
              " ('Hokage', 'NNP'),\n",
              " ('Naruto', 'NNP'),\n",
              " ('the', 'DT'),\n",
              " ('son', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('Minato', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Kushina', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Konoha', 'NNP'),\n",
              " ('village', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('having', 'VBG'),\n",
              " ('Six', 'NNP'),\n",
              " ('Sage', 'NNP'),\n",
              " ('Path', 'NNP'),\n",
              " ('power', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('kurama', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1hY21btfSYr"
      },
      "source": [
        "#**Named Entity Recognition:**\n",
        "Named Entity Recognition is used to extract information from unstructured text. It is used to classify entities present in a text into categories like a person, organization, event, places, etc. It gives us detailed knowledge about the text and the relationships between the different entities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89xSOloTdp1k",
        "outputId": "c81f8f8b-b7fb-4f67-fa42-f68b90de5878"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk\n",
        "\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S26cqUkNendS",
        "outputId": "e23b177f-a6a5-4282-df79-62b32572c5c6"
      },
      "source": [
        "def named_entity_recognition(text):\n",
        "\t# tokenize the text\n",
        "\tword_tokens = word_tokenize(text)\n",
        "\n",
        "\t# part of speech tagging of words\n",
        "\tword_pos = pos_tag(word_tokens)\n",
        "\n",
        "\t# tree of word entities\n",
        "\tprint(ne_chunk(word_pos))\n",
        "\n",
        "text = 'The Sannin, otherwise known as the Legendary Three Ninja, were the students of the Third Hokage, Hiruzen Sarutobi. They are Jiraiya, Tsunade, and Orochimaru. All three are incredibly talented shinobi'\n",
        "named_entity_recognition(text)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (GPE Sannin/NNP)\n",
            "  ,/,\n",
            "  otherwise/RB\n",
            "  known/VBN\n",
            "  as/IN\n",
            "  the/DT\n",
            "  Legendary/NNP\n",
            "  Three/NNP\n",
            "  Ninja/NNP\n",
            "  ,/,\n",
            "  were/VBD\n",
            "  the/DT\n",
            "  students/NNS\n",
            "  of/IN\n",
            "  the/DT\n",
            "  Third/NNP\n",
            "  Hokage/NNP\n",
            "  ,/,\n",
            "  (PERSON Hiruzen/NNP Sarutobi/NNP)\n",
            "  ./.\n",
            "  They/PRP\n",
            "  are/VBP\n",
            "  (PERSON Jiraiya/NNP)\n",
            "  ,/,\n",
            "  (PERSON Tsunade/NNP)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  (ORGANIZATION Orochimaru/NNP)\n",
            "  ./.\n",
            "  All/DT\n",
            "  three/CD\n",
            "  are/VBP\n",
            "  incredibly/RB\n",
            "  talented/VBN\n",
            "  shinobi/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oS8v8G0ovkL"
      },
      "source": [
        "#**Relation Extraction**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2i9E5sowk2"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}